{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Lmjw Blog","text":"<p>Welcome to my personal notes and blog.</p>"},{"location":"tags/","title":"Tags","text":"<p>This site uses tags to group related posts.</p> <p>Each blog post can define tags in a YAML front matter block at the top of the file, for example:</p> <pre><code>---\ntitle: An experiment using golang and python to execute command in docker\ntags: [golang, python, docker, subprocess, bash]\ndate: 2017-11-26\n---\n</code></pre> <p>With the current MkDocs + Material configuration, these tags are shown near the top of the page as visual labels, making your blog look more like a professional technical site.</p>"},{"location":"tags/#how-to-use-tags-for-new-posts","title":"How to use tags for new posts","text":"<p>When you create a new post under <code>docs/blog/</code>, include a <code>tags</code> field in the YAML front matter:</p> <pre><code>---\ntitle: My new post\ntags: [notes, rust, grpc]\ndate: 2025-11-28\n---\n</code></pre> <p>After that:</p> <ul> <li>The tags will appear on the post page itself.</li> <li>The built-in search will help you find posts by tag names and content.</li> </ul> <p>You can freely choose any tags that make sense for your writing (e.g. <code>golang</code>, <code>python</code>, <code>docker</code>, <code>kubernetes</code>, <code>learning</code>, <code>os-dev</code>).</p>"},{"location":"blog/","title":"Blog","text":"<p>Welcome to my blog.</p> <p>New posts live under this folder as Markdown files, for example:</p> <ul> <li><code>docs/blog/my-new-post.md</code></li> </ul>"},{"location":"blog/#posts","title":"Posts","text":"<ul> <li>OOP design notes \u2014 2022-04-05</li> <li>Simple prost use guid \u2014 2021-12-28</li> <li>Painless key mapping on windows \u2014 2021-11-20</li> <li>Learning OS dev notes \u2014 2021-05-17</li> <li>Data Oriented Design \u2014 2019-11-24</li> <li>Intro to deep learning notes \u2014 2019-06-12</li> <li>A explanation of Open ssl certification \u2014 2018-01-05</li> <li>A python example of realizing secure grpc communication \u2014 2018-01-05</li> <li>A simple example of using docker container to realize the grpc client and server communication \u2014 2017-12-26</li> <li>Kubernete's tutorial notes \u2014 2017-12-06</li> <li>Install GMP on windows 10 machine \u2014 2017-11-30</li> <li>python subprocess \u2014 2017-11-28</li> <li>An experiment using golang and python to execute command in docker \u2014 2017-11-26</li> <li>\u6211\u7684\u8f6f\u4ef6\u6e05\u5355 \u2014 2016-03-05</li> <li>Markdown Style Guide \u2014 2014-03-03</li> <li>common knowledge cheat sheet</li> </ul> <p>To add a new post:</p> <ol> <li>Create a new Markdown file in this directory, e.g. <code>my-new-post.md</code>.</li> <li>Optionally add a bullet link to it in the list above.</li> <li>Commit and push your changes to the <code>main</code> branch.</li> </ol> <p>Once you push, GitHub Actions will build the site with MkDocs and deploy it to GitHub Pages automatically.</p>"},{"location":"blog/2014-3-3-Markdown-style-guide/","title":"Markdown Style Guide","text":"<p>This is a forked syntax cheatsheet for Jekyll.</p> <p>View the markdown used to create this post.</p> <pre><code>[View the markdown used to create this post](https://raw.githubusercontent.com/barryclark/www.jekyllnow.com/gh-pages/_posts/2014-6-19-Markdown-Style-Guide.md).\n</code></pre> <p>This is a paragraph, it's surrounded by whitespace. Next up are some headers, they're heavily influenced by GitHub's markdown style.</p>","tags":["Markdown CheatSheet"]},{"location":"blog/2014-3-3-Markdown-style-guide/#header-2-h1-is-reserved-for-post-titles","title":"Header 2 (H1 is reserved for post titles)","text":"<pre><code>## Header 2 (H1 is reserved for post titles)##\n</code></pre>","tags":["Markdown CheatSheet"]},{"location":"blog/2014-3-3-Markdown-style-guide/#header-3","title":"Header 3","text":"<pre><code>### Header 3\n</code></pre>","tags":["Markdown CheatSheet"]},{"location":"blog/2014-3-3-Markdown-style-guide/#header-4","title":"Header 4","text":"<pre><code>#### Header 4\n</code></pre> <p>A link to Jekyll Now. A big ass literal link http://github.com/barryclark/jekyll-now/</p> <pre><code>A link to [Jekyll Now](http://github.com/barryclark/jekyll-now/). A big ass literal link &lt;http://github.com/barryclark/jekyll-now/&gt;\n</code></pre> <p>An image, located within <code>image/openssl_key_diagram.png</code></p> <p></p> <pre><code>![an image alt text](image/openssl_key_diagram.png \"an image title\")\n</code></pre> <ul> <li>A bulletted list</li> <li>alternative syntax 1</li> <li>alternative syntax 2</li> <li> <p>an indented list item</p> </li> <li> <p>An</p> </li> <li>ordered</li> <li>list</li> </ul> <pre><code>* A bulletted list\n- alternative syntax 1\n+ alternative syntax 2\n  - an indented list item\n\n1. An\n2. ordered\n3. list\n</code></pre> <p>Inline markup styles:</p> <ul> <li>italics</li> </ul> <pre><code>- _italics_\n</code></pre> <ul> <li>bold</li> </ul> <pre><code>- **bold**\n</code></pre> <ul> <li><code>code()</code></li> </ul> <pre><code>- `code()`\n</code></pre> <p>Blockquote</p> <pre><code>&gt; Blockquote\n</code></pre> <p>Nested Blockquote</p> <pre><code>&gt;&gt; Nested Blockquote\n</code></pre> <p>Syntax highlighting can be used with triple backticks, like so:</p> <pre><code>/* Some pointless Javascript */\nvar rawr = [\"r\", \"a\", \"w\", \"r\"];\n</code></pre> <p>Use two trailing spaces on the right to create linebreak tags  </p> <p>Finally, horizontal lines</p> <pre><code>----\n</code></pre> <pre><code>****\n</code></pre>","tags":["Markdown CheatSheet"]},{"location":"blog/2016-03-05-my-favourit-softwares/","title":"\u6211\u7684\u8f6f\u4ef6\u6e05\u5355","text":"<p>\u4e3a\u4e86\u65b9\u4fbf\u67e5\u770b\uff0c\u6211\u5c06\u672c\u8d34\u6536\u5f55\u5728\u6211\u7684\u535a\u5ba2\u4e2d\uff0c\u8bf7\u652f\u6301\u6b64\u8d34\u7684\u539f\u4f5c\u8005\uff0c\u7530\u7426\u7684\u535a\u5ba2</p> <p>\u6574\u7406\u4e86\u4e0b\u81ea\u5df1\u559c\u6b22\u7684\u8f6f\u4ef6\uff0c\u5217\u51fa\u4e86\u8fd9\u4e2a\u6e05\u5355\u3002</p> <p>\u6211\u7684\u539f\u5219\u662f\uff1a\u5c3d\u91cf\u4f7f\u7528\u514d\u8d39\u5f00\u6e90\u8f6f\u4ef6\uff0c\u4e0d\u4f7f\u7528\u7834\u89e3\u8f6f\u4ef6\u3002</p> <p>\u672c\u6587\u957f\u671f\u66f4\u65b0\uff0c\u6b22\u8fce\u63a8\u8350\u3002</p>","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#windows","title":"Windows","text":"","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#picpick","title":"PicPick","text":"<p>\u745e\u58eb\u519b\u5200\u4e00\u6837\u7684\u8f6f\u4ef6\u3002\u56fe\u50cf\u7f16\u8f91\u5668\uff0c\u989c\u8272\u9009\u62e9\u5668\uff0c\u989c\u8272\u8c03\u8272\u677f\uff0c\u50cf\u7d20\u6807\u5c3a\uff0c\u91cf\u89d2\u5668\uff0c\u7784\u51c6\u7ebf\u548c\u767d\u677f\u7b49\u7b49\uff0c\u582a\u79f0\u5168\u80fd\u7684\u8bbe\u8ba1\u5de5\u5177\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5b83\u5bf9\u4e2a\u4eba\u7528\u6237\u662f\u5b8c\u5168\u514d\u8d39\u7684\u3002</p> <p></p> <p>\u5b98\u7f51\u94fe\u63a5</p>","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#putty","title":"PuTTY","text":"<p>Putty \u662f\u4e00\u4e2a\u514d\u8d39\u7684\uff0cWindows 32 \u5e73\u53f0\u4e0b\u7684 telnet\u3001rlogin \u548c ssh \u5ba2\u6237\u7aef\u3002</p> <p></p> <p>\u5b98\u7f51\u94fe\u63a5</p>","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#advanced-ip-scanner","title":"Advanced ip Scanner","text":"<p>\u662f\u53ef\u4ee5\u5728\u5feb\u901f\u626b\u63cf\u5c40\u57df\u7f51\u8ba1\u7b97\u673a\u4fe1\u606f\u7684\u7f51\u7edc IP \u626b\u63cf\u5de5\u5177\uff0c\u5bf9\u4e8e\u5bfb\u627e\u4e00\u4e9b\u6ca1\u6709\u663e\u793a\u7684\u8bbe\u5907\uff08\u6bd4\u5982\u6ca1\u63a5\u5c4f\u5e55\u7684\u6811\u8393\u6d3e\uff09IP \u7279\u522b\u6709\u7528\u3002</p> <p></p>","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#oracle-vm-virtualbox","title":"Oracle VM VirtualBox","text":"<p>VMware Workstation \u7684\u7edd\u4f73\u5f00\u6e90\u66ff\u4ee3\u54c1\uff0c\u5341\u5206\u9002\u5408\u5728 Windows \u4e2d\u865a\u62df Linux \u7cfb\u7edf\u73af\u5883\u3002</p> <p></p> <p>\u5b98\u7f51\u94fe\u63a5</p>","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#cmder","title":"Cmder","text":"<p>cmd \u66ff\u4ee3\u54c1\uff0c\u80fd\u6700\u5927\u5316\uff0c\u6807\u7b7e\u9875\u4ee5\u53ca\u975e\u5e38\u4e0d\u9519\u7684\u5b9a\u5236\u6027\u3002</p> <p></p> <p>\u5b98\u7f51\u94fe\u63a5</p>","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#typora","title":"typora","text":"<p>Windows \u4e0b\u975e\u5e38\u597d\u7528\u7684 Markdown \u7f16\u8f91\u5668\uff0c\u652f\u6301\u591a\u79cd\u4e3b\u9898\uff0c\u66f4\u68d2\u7684\u662f\u8fd8\u652f\u6301 YAML \u5934\u6587\u4ef6\u3002</p> <p>\u5b98\u7f51\u94fe\u63a5</p>","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#mp3tag","title":"mp3Tag","text":"<p>MP3 \u6587\u4ef6 ID3-Tag \u4fe1\u606f\u4fee\u6539\u5668\u3002\u53ef\u4ee5\u4fee\u6539 MP3 \u6587\u4ef6\u4e2d\u7684\u66f2\u540d\u3001\u6f14\u5531\u8005\u3001\u4e13\u96c6\u3001\u5e74\u6708\u3001\u6d41\u6d3e\u3001\u6ce8\u91ca\u7b49\u4fe1\u606f\uff0c\u6b4c\u66f2\u6536\u85cf\u8005\u7684\u5229\u5668\u3002</p> <p>\u5b98\u7f51\u94fe\u63a5</p>","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#linux","title":"Linux","text":"","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#zsh-with-oh-my-zsh","title":"zsh (with Oh My Zsh)","text":"<p>\u6bd4 bash \u66f4\u597d\u7528\u7684 shell\u3002\u66f4\u5f3a\u7684\u53ef\u914d\u7f6e\u6027\uff0c\u66f4\u5f3a\u7684 tab \u8865\u5168\uff0c\u8fd8\u9644\u5e26 git \u652f\u6301\u3002\u518d\u52a0\u4e0aOh My Zsh\u7684\u5b58\u5728\uff0czsh \u5df2\u7ecf\u76f8\u5f53\u6613\u7528\u4e86\u3002</p> <p></p> <p>Oh My Zsh \u9879\u76ee\u94fe\u63a5</p>","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#tmux","title":"Tmux","text":"<p>SSH \u6700\u4f73\u4f34\u4fa3\u3002</p> <p>\u5b98\u7f51\u94fe\u63a5</p>","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#graphviz","title":"Graphviz","text":"<p>\u201c\u6240\u60f3\u5373\u6240\u5f97\u201d\u7684\u753b\u56fe\u5de5\u5177\uff0c\u7531\u5927\u540d\u9f0e\u9f0e\u7684\u8d1d\u5c14\u5b9e\u9a8c\u5ba4\u5f00\u53d1\u3002\u7b80\u5355\u7684\u6765\u8bb2\u5c31\u662f\u4e00\u6b3e\u4f7f\u7528\u811a\u672c\u8bed\u8a00\u6765\u8fdb\u884c\u7ed8\u56fe\u7684\u5de5\u5177\u3002</p> <p></p> <p>\u5b98\u7f51\u94fe\u63a5</p> <p>DOT\u811a\u672c\u8bed\u8a00</p>","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#grapheasy","title":"Graph::Easy","text":"<p>\u8ddf Graphviz \u7c7b\u4f3c\u7684\u8f6f\u4ef6\u3002\u7528\u5b83\u53ef\u4ee5\u5f88\u65b9\u4fbf\u7684\u7ed8\u5236\u51fa\u5b57\u7b26\u7248\u7684\u6d41\u7a0b\u56fe\uff0c\u5f88\u9002\u5408\u4ee3\u7801\u6ce8\u91ca\u3002\u5f53\u7136\uff0c\u5b83\u7684\u529f\u80fd\u8fdc\u4e0d\u6b62\u8fd9\u4e9b\u3002</p> <p>{% highlight text%} +------+     +--------+      .............     +---------+ | Bonn | --&gt; | Berlin |  --&gt; : Frankfurt : --&gt; | Dresden | +------+     +--------+      .............     +---------+                :                :                v              +---------+     +---------+              | Potsdam | ==&gt; | Cottbus |              +---------+     +---------+</p> <p>GitHub \u9879\u76ee\u9875</p>","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#coding","title":"Coding","text":"","tags":["Tools"]},{"location":"blog/2016-03-05-my-favourit-softwares/#visual-studio-code","title":"Visual Studio Code","text":"<p>\u5fae\u8f6f\u51fa\u54c1\uff0c\u548c atom \u4e00\u6837\u57fa\u4e8e electron\uff0c\u4f46\u6bd4 atom \u6d41\u7545\u3002\u9875\u9762\u975e\u5e38\u9177\uff0c\u63d2\u4ef6\u4e5f\u5df2\u7ecf\u975e\u5e38\u5168\u9762\u4e86\uff0c\u8d8a\u6765\u8d8a\u591a\u7684\u524d\u7aef\u5de5\u7a0b\u5e08\u5f00\u59cb\u8f6c\u5411\u5b83\u4e86\u3002</p> <p>\u5b98\u7f51\u94fe\u63a5</p>","tags":["Tools"]},{"location":"blog/2017-11-26-blog-docker-python-golang/","title":"An experiment using golang and python to execute command in docker","text":"","tags":["golang","python","docker","subprocess","bash"]},{"location":"blog/2017-11-26-blog-docker-python-golang/#description","title":"Description:","text":"<p>Using golang to execute python code, which can in turn execute docker command to control docker container.</p> <p>The overall idea is to execute some python script in golang environment using golang <code>exec</code>, and this python script contain some docker commands (bash). So the overall flow of execution is:</p> <p>[bash terminal] ===&gt; [golang.exec] ===&gt; [python.subprocess] ===&gt; [bash] ===&gt; [docker command]</p> <p>The issue occurs. </p> <p>the input device is not a TTY.  If you are using mintty, try prefixing the command with 'winpty'</p>","tags":["golang","python","docker","subprocess","bash"]},{"location":"blog/2017-11-26-blog-docker-python-golang/#test-command","title":"TEST COMMAND","text":"<pre><code>docker run -it ubuntu bash\n</code></pre>","tags":["golang","python","docker","subprocess","bash"]},{"location":"blog/2017-11-26-blog-docker-python-golang/#environment-setting","title":"Environment setting:","text":"<ul> <li>windows 10 home</li> <li>docker toolbox</li> <li>Git: git version 2.9.0.windows.1</li> <li>Python: Python 3.6.3, Anaconda custom (64-bit)</li> <li>golang: go version go1.9.2 windows/amd64</li> </ul>","tags":["golang","python","docker","subprocess","bash"]},{"location":"blog/2017-11-26-blog-docker-python-golang/#failed-example","title":"Failed example:","text":"<p>running under default git-bash environment in windows 10:</p> <pre><code>$ docker run -it ubuntu bash\n</code></pre> <p>&gt;&gt;&gt; the input device is not a TTY.  If you are using mintty, try prefixing the command with 'winpty'</p>","tags":["golang","python","docker","subprocess","bash"]},{"location":"blog/2017-11-26-blog-docker-python-golang/#similar-issue-has-been-mentioned-in-this-docker-tutorial-and-was-explained-with-a-proposed-solution-by-will-anderson-in-his-blog","title":"Similar issue has been mentioned in this docker tutorial and was explained with a proposed solution by Will Anderson in his blog.","text":"","tags":["golang","python","docker","subprocess","bash"]},{"location":"blog/2017-11-26-blog-docker-python-golang/#ideal-successful-case","title":"Ideal successful case","text":"<pre><code>&gt;&gt;&gt; go-command()\n        # inside go-command()\n            go.exec(\"python script\")\n                # inside python script\n                    python.subprocess(\"bash\",\"docker run -it ubuntu bash\")\n</code></pre> <p>The idea is by execute a command in a CLI created by golang, it will call a execution of a python script, and this python script can then subprocess execute the <code>docker run -it ubuntu bash</code> in the bash terminal.</p>","tags":["golang","python","docker","subprocess","bash"]},{"location":"blog/2017-11-26-blog-docker-python-golang/#experiment","title":"Experiment","text":"<ol> <li>the first experiment is to get rid of \"is not a tty\" error and make it work in python script.  Because this command(<code>docker run -it ubuntu bash</code>) is not working in the git-bash terminal, it will never (I think) work if you open idle or any python CLI for this git-bash. So the way you open the python CLI is important.</li> </ol> <p>The easiest solution is to use the Docker Quickstart Terminal to open the python CLI. In the working directory, you can create a simple python subprocess function and name this file <code>pyCmd.py</code>.</p> <p>```python    from subprocess import Popen, PIPE, STDOUT</p> <p>def pyDockerCmd(command):        bash_exec = 'bash.exe'        return Popen([bash_exec, '-c', f'{command}'], \\                stdout = PIPE, stderr = PIPE, encoding='utf-8').communicate()    ```</p> <p>in the command line interface (here I use Docker Quickstart terminal), you can test the result:</p> <p><code>bash    $ python -c \"import pyCmd; print(pyCmd.pyDockerCmd('docker run -it ubuntu bash'))\"</code></p> <p>after execute, you will see something like this. </p> <p></p> <p>If you have something like this, it means at least you get rid of the \"tty\" error, which is annoying. </p> <p>This \"non-response\" situation is actually because of the \"print\" command print all the response after the docker bash session end. You can try type \"ls\", \"pwd\",and \"exit\". Since \"exit\" command will quit the bash terminal, you will see all the responses after you type \"exit\".    </p> <p>Now we know at least the python can interact with the \"docker\" freely without the \"TTY\" error. It is not perfect, we can see the responsivity is crappy. But at least we know it's working.</p> <p>[bash terminal(Docker quickstart terminal)] ~~===&gt; [golang.exec]~~ ===&gt; [python.subprocess] ===&gt; [bash] ===&gt; [docker command]</p> <ol> <li>Now, if you wrap this python function into golang, and execute this in the Docker quickstart terminal, you will probably still see:</li> </ol> <p>('', \"the input device is not a TTY.  If you are using mintty, try prefixing the command with 'winpty'\\n\")</p> <p>wtf?</p> <p>The golang function (<code>testGoPy.go</code>) is:</p> <p>```go    package main</p> <p>import (     \"fmt\"     \"log\"     \"os/exec\"    )</p> <p>func main() {     out, err := exec.Command(\"python\",\"-c\",\"import pyCmd; print(pyCmd.pyDockerCmd('docker run -it ubuntu bash'))\").Output()</p> <pre><code>if err != nil {\n    log.Fatal(err)\n}\nfmt.Printf(string(out))\n</code></pre> <p>}    ```</p> <p></p> <p>Why is this?</p> <p>I stuck here for a while, until I found this post which is kind related to my problem. If we think this way, the command we want to execute by golang is <code>docker run -it ubuntu bash</code>, which is an interactive session, and it needs input and return output. However the golang <code>exec.Command(...).Output()</code> seems have no option of taking Stdin input. Hence, we need to modify the golang code so it can take stdin put.</p> <p>The modified code is shown as the following.</p> <p>```go    package main</p> <p>import (     \"fmt\"     \"os\"     \"os/exec\"    )</p> <p>func main() {     runCommand(\"python\",\"-c\",\"import pyCmd; print(pyCmd.pyDockerCmd('docker run -it ubuntu bash'))\")    }</p> <p>func runCommand(cmdName string, arg ...string) {        cmd := exec.Command(cmdName, arg...)        cmd.Stdout = os.Stdout        cmd.Stderr = os.Stderr        cmd.Stdin = os.Stdin        err := cmd.Run()        if err != nil {            fmt.Printf(err.Error())            os.Exit(1)        }    }    ```</p> <pre><code>if you compile this and execute the this code in **Docker quickstart terminal**, it will work as before. (Similar to figure1 &amp;2)\n</code></pre> <p></p> <p>Although it is not perfect, we have solved the problem of \"is not a TTY\".</p>","tags":["golang","python","docker","subprocess","bash"]},{"location":"blog/2017-11-26-blog-docker-python-golang/#to-summarize-the-issue","title":"To summarize the issue","text":"<pre><code>  1. Try to use the \"Docker quickstart terminal\" instead of \"git bash\". \n  2. in the golang ```exec``` command, instead of using ```exec.Command().Output()``` directly execute the command, using ```exec.run()``` and set up the **Stdin** and Stdout before execute the command.\n</code></pre> <p>these two steps help me to solve my problem.</p>","tags":["golang","python","docker","subprocess","bash"]},{"location":"blog/2017-11-26-blog-docker-python-golang/#further-steps","title":"Further steps","text":"<p>I know this piece of code is imperfect and there are many things to be improved. But at least this annoying \"is not a tty\" problem is solved. I will further investigate the python subprocess package and try to get more understandings about it.</p>","tags":["golang","python","docker","subprocess","bash"]},{"location":"blog/2017-11-28-python-subprocess/","title":"python subprocess","text":"","tags":["python","subprocess","CLI"]},{"location":"blog/2017-11-28-python-subprocess/#python-subprocess-examples","title":"Python subprocess examples","text":"","tags":["python","subprocess","CLI"]},{"location":"blog/2017-11-28-python-subprocess/#description","title":"Description","text":"<p>This is a collection of python subprocess examples for easy usage. Although I found the python documents are very comprehensive, I found there is not much  examples of showing how to use. This document act as a note of how to use python subprocess package.</p>","tags":["python","subprocess","CLI"]},{"location":"blog/2017-11-28-python-subprocess/#environment-settings","title":"Environment settings","text":"OS Windows 10 home python Anaconda, python 3.6.3","tags":["python","subprocess","CLI"]},{"location":"blog/2017-11-28-python-subprocess/#main-functions","title":"Main functions","text":"<p>the code is executed in IDLE command line window.</p> <p>```python </p> <p>import subprocess as sb bash_exec = \"C:\\Program Files\\Git\\bin\\bash.exe\" sb.run([bash_exe, '-c','pwd'], stdout=sb.PIPE)   ```</p> <p>CompletedProcess(args=['C:\\Program Files\\Git\\bin\\bash.exe', '-c', 'pwd'], returncode=0, stdout=b'/c/Users/xxx/Anaconda3/Scripts\\n')</p> <p>NOTE:</p> <ul> <li>need to point to bash exe</li> <li>bash needs a \"-c\" condition in order to run it, otherwise a returncode=126 will return. Cannot using -i tag for bash command execution.</li> <li> <p>return result will not be shown if <code>stdout</code> is not set. </p> </li> <li> </li> </ul> <p>However, I personally feel that the Popen is the most important tool of this subprocess package.</p> <p>Basic syntex </p> <p>```python</p> <p>p = sb.Popen([bash_exe, '-c', 'pwd'], stdout=sb.PIPE, stderr=sb.PIPE) p.communicate()   ```</p> <p>(b'/c/Users/xxx/Anaconda3/Scripts\\n', b'')</p> <p>this is working. </p> <p>The other one I thought it would work but actually not</p> <p>```python </p> <p>p = sb.Popen(['-c','pwd'],executable=bash_exe, stdout=sb.PIPE, stderr=sb.PIPE) p.communicate()   ```</p> <p>(b'', b'/usr/bin/pwd: /usr/bin/pwd: cannot execute binary file\\n')</p> <p>The error turn out to be a bit wired. For now, I am not sure how is this happened.</p> <p><code>env</code> might be one very useful attributes when some info needs to be preloaded before executing the command.</p> <p>```python </p> <p>p = sb.Popen([bash_exe, '-c', 'echo $NAME'], stdout=sb.PIPE, stderr=sb.PIPE) p.communicate()   ```</p> <p>(b'\\n', b'')</p> <p>```python </p> <p>p = sb.Popen([bash_exe, '-c', 'echo $NAME'], stdout=sb.PIPE, stderr=sb.PIPE, env = {'NAME':'superman'}) p.communicate()   ```</p> <p>(b'superman\\n', b'')</p> <p>context manager</p> <p><code>python   with sb.Popen([bash_exe, '-c', 'echo $NAME'], stdout=sb.PIPE, stderr=sb.PIPE, env = {'NAME':'superman'}) as proc:     proc.communicate()</code></p> <p>(b'superman\\n', b'')</p> <p>Not working:</p> <p>```python</p> <p>with sb.Popen([bash_exe, '-c',], stdout=sb.PIPE, stderr=sb.PIPE, stdin = sb.PIPE, env = {'NAME':'superman'}) as proc:     proc.communicate(input=input())</p> <p>pwd   ```</p> <p>(b'', b'/usr/bin/bash: -c: option requires an argument\\n')</p> <p>Eh, looks I can write a basic bash CLI?</p> <p>```python   import subprocess as sb</p> <p>command = ''   kernal = \"C:\\Program Files\\Git\\bin\\bash.exe\"</p> <p>while command!=\"exit\":       command = input('%: ')       proc = sb.Popen([kernal,'-c',command], stdout=sb.PIPE, stderr=sb.PIPE, encoding = 'utf-8')       out,err = proc.communicate()       if err =='':           print(out)       else:           print(err)   ```</p> <p>However, if you input \"cd\" command, it actually doesn't change its directory. SO, this CLI sucks.</p> <p>One easy solution is to use some libraries such as Pespect on Windows. </p> <p>NOTE:</p> <p>(TODO)</p> <p>this seems a good solution for building an interactive shell. </p> <p>\u200b</p>","tags":["python","subprocess","CLI"]},{"location":"blog/2017-11-28-python-subprocess/#subprocessrun","title":"subprocess.run()","text":"","tags":["python","subprocess","CLI"]},{"location":"blog/2017-11-28-python-subprocess/#subprocesspopen","title":"subprocess.Popen(*)","text":"","tags":["python","subprocess","CLI"]},{"location":"blog/2017-11-30-Install-GMP-on-windows10-machine/","title":"Install GMP on windows 10 machine","text":"<p>Recently, I was trying to install GMP library on my windows 10 machine.</p> <p>The first problem that I was facing is </p> <p>'gcc' is not recognized as an internal or external command, operable program or batch file.\"</p> <p>Then I did some searches and I found this page which showed how to install GMP on windows. However, it is a bit outdated, I still encounter some problems in following its steps. Luckily I figured out how to solve the problems and installed the GMP successfully. </p> <p>In the guide, they recommended to use Dev-C++ to get gcc compiler. I had tried this method, however it didn't work. It returned some error when I was trying to run <code>./configure</code>. </p> <p>Here I will suggest a different approach, instead of using the Dec-C++, I recommend to install MinGW following the guild from MinGW website. You need to install both MinGW and MSYS. </p> <p>After installation, if you open window cmd terminal, you may still not find \"gcc\". The trick is to go to the directory (\"C:\\MinGW\\msys\\1.0\\\") (if you install MinGW in its default directory) and double click \"msys.bat\" then a terminal is popped out. In this terminal, you will be able to find gcc command.</p> <p>The next step is to use \"cd\" command to go to the GMP directory. (My path is :\"C:\\c++\\gmp\\gmp-6.1.2\\\"). In this directory, run \"./configure\" and it should work correctly. I did followed the guide to modify the make files, but I suspect it can work without changing.</p> <p>Update fix</p> <p>: You must  fix an error which currently exists in the Makefiles. You must do one of the following:</p> <ol> <li>Before running ./configure (step 4), go to C:\\c++\\GMP\\GMP-4.2.1\\mpn*Makeasm.am and go to the last line of the file. If you find --m4=\"$(M4)\" in the middle of it, change it to --m4=$(M4)*. That is, remove the double quote marks,</li> <li>After running ./configure (step 4), go to C:\\c++\\Includes\\GMP\\GMP-4.2.1\\mpn*Makefile and also C:\\c++\\Includes\\GMP\\GMP-4.2.1\\tests*Makefile and make the same replacements described just above, although not quite at the last line. Change --m4=\"$(M4)\" to --m4=$(M4)**.</li> </ol> <p>Instead of run \"./configure\", I did run \"./configure --enable-cxx\". However, in order to configure successfully with \"enable cxx\", you need to install not only gcc, but also g++ compiler as well. To install g++ compiler, you can simply open \"MinGW installation manager\" and find mingw gcc g++ compiler and install it. </p> <p>After configure run successfully, you can type</p> <pre><code>make\n</code></pre> <p>and </p> <pre><code>make install\n</code></pre> <p>then finally</p> <pre><code>make check\n</code></pre> <p>I didn't face any new issues. All the tests have been passed. So the gmp is successfully installed.</p>","tags":["GMP"]},{"location":"blog/2017-11-30-Install-GMP-on-windows10-machine/#summary","title":"Summary","text":"<p>In summary, the trick is to install mingw and msys properly. If you follow mingw page properly, you should not experience any issue. (At least I didn't). SO this basically the guild for installing GMP on windows 10. </p>","tags":["GMP"]},{"location":"blog/2017-12-06-Kubernetes/","title":"Some concepts of Kubernetes Clusters","text":"<ul> <li> <p>Kubernetes cluster(KC) can be analogy to the conventional computational cluster, which includes many computers and to work as a single unit. </p> </li> <li> <p>application runs on the KC needs to be containerized.</p> </li> <li> <p>the program organizing  the KC, namely Kubernete, manage the deployment and make containerized application run in KC in a more efficient way.</p> </li> </ul>","tags":["Kubernetes","docker"]},{"location":"blog/2017-12-06-Kubernetes/#kubernetes-cluster-structure","title":"Kubernetes cluster structure","text":"<ul> <li>Master ( act as a manager): coordinate the cluster</li> <li>Nodes (act as worker, the job of work is to run the containerize application)</li> </ul>","tags":["Kubernetes","docker"]},{"location":"blog/2017-12-06-Kubernetes/#master-responsibilities-coordinate-activities-in-cluster","title":"Master responsibilities : coordinate activities in cluster","text":"<ul> <li>scheduling application</li> <li>maintaining application states</li> <li>scaling application</li> <li>rolling new updates</li> </ul>","tags":["Kubernetes","docker"]},{"location":"blog/2017-12-06-Kubernetes/#nodeworker","title":"Node(worker)","text":"<ul> <li>definition of Node:   A node can be a VM or a physical computer that serves as a worker machine in a KC. So, you can think node is just a physical laptop/desktop.</li> <li>What node have? | name       | description                              | Analogy | | ---------- | ---------------------------------------- | ------- | | Kubelet    | this guy does two thing: 1. managing the node; 2. communicate with master |         | | Docker/rkt | tool to handle containerized application(containers) |         |</li> </ul>","tags":["Kubernetes","docker"]},{"location":"blog/2017-12-06-Kubernetes/#kubernetes-application-deployment","title":"Kubernetes application deployment","text":"<ol> <li>Kubernetes deployment process</li> <li>tell the master to start application containers. </li> <li>then master schedules the containers to run on the cluster's nodes.</li> <li>master exposes the Kubernetes' API. The node also communicate with this API</li> <li>end user can use Kubernete's API to interact with cluster</li> <li>Kubernetes can be deployed on either physical or vertial machines</li> <li>Kubernetes development,Minikube</li> <li>one simple Kubernetes implementation(simple cluster only contains one node) </li> <li>Minikube CLI provide basic bootstrapping operations for cluster (start, stop, status and delete)</li> </ol>","tags":["Kubernetes","docker"]},{"location":"blog/2017-12-06-Kubernetes/#kubernetes-interactive-tutorial","title":"Kubernetes interactive tutorial","text":"","tags":["Kubernetes","docker"]},{"location":"blog/2017-12-06-Kubernetes/#module-1-creating-a-cluster","title":"Module 1: Creating a cluster","text":"<ol> <li>check the minikube. Type the commands in terminal</li> </ol> <pre><code>minikube version\n</code></pre> <ol> <li>start a cluster</li> </ol> <pre><code>minikube start\n</code></pre> <ol> <li>to interact with Kubernetes, we will use the command line interface, kubectl. To check whether Kubectl is installed, you can run kubectl version check.</li> </ol> <pre><code>kubectl version\n</code></pre> <ol> <li>to see the cluster details, we can type the command</li> </ol> <pre><code>kubectl cluster-info\n</code></pre> <ol> <li>to view the cluster's nodes, we can type the command</li> </ol> <pre><code>kubectl get nodes\n</code></pre>","tags":["Kubernetes","docker"]},{"location":"blog/2017-12-06-Kubernetes/#module-2-deploy-an-application-using-kubectl","title":"Module 2. Deploy an Application using Kubectl","text":"","tags":["Kubernetes","docker"]},{"location":"blog/2017-12-06-Kubernetes/#kubernetes-application-deployments","title":"Kubernetes application deployments","text":"<ol> <li>running your Kubernetes cluster</li> <li>deploy containerized application on top of it. This requires you to create a  Kubernetes Deployment configuration.</li> <li>Deployment configuration instruct Kubernetes how to create and update instances of your application.</li> <li>Once the deployment is created by you. the Kubernetes master loads the mentioned application instances into individual nodes.</li> </ol>","tags":["Kubernetes","docker"]},{"location":"blog/2017-12-06-Kubernetes/#after-kubernetes-applications-are-deployed","title":"After Kubernetes applications are deployed","text":"<ol> <li>once the application instances are created, a Kubernetes Deployment Controller continuously monitors those instances. </li> <li>if a node goes down or get deleted, the Deployment Controller replaces it. this provides a self-healing mechanism to address machine failure or maintainance.</li> </ol>","tags":["Kubernetes","docker"]},{"location":"blog/2017-12-06-Kubernetes/#now-lets-try-to-deploy-your-first-app-on-kubernetes","title":"Now, let's try to deploy your first app on Kubernetes","text":"<p>Never the less, here's a diagram of showing the relationships between different components of Kubernetes cluster.  1. you can create and manage a deployment by using kubernetes command line interface, kubectl.  2. when you create a deployment, you need to specify the container image for your application and how many replicas that you want to run. </p>","tags":["Kubernetes","docker"]},{"location":"blog/2017-12-06-Kubernetes/#first-deployment-example-module-2","title":"First deployment example, Module 2","text":"<ul> <li>** Node.js** application packaged in a Docker container. source code</li> <li>goal: deploy your first app on Kubernetes using kubectl.</li> <li>Kubectl basic commands</li> </ul> command description <code>kubectl version</code> get the version of kubectl <code>kubectl get nodes</code> view the nodes in cluster <ol> <li>run an app using Kubectl</li> </ol> <pre><code>kubectl run &lt;command&gt;\n</code></pre> <p>example:</p> <pre><code>kubectl run kubernetes-bootcamp --image=docker.io/jocatalin/kubernetes-bootcamp:v1 --port=8080\n</code></pre> <p>What this previous command did?</p> <ul> <li>find the available nodes that can be used to run the application</li> <li>schedule the application to run on that node</li> <li> <p>configure the cluster to reschedule the instance on a new Node when needed</p> </li> <li> <p>to list your deployments</p> </li> </ul> <pre><code>kubectl get deployments\n</code></pre> <ol> <li>View our apps</li> <li> <p>pods: running inside Kubernetes are running on a private, isolated network. (What the fuck is this pods?). By default, they are visible from other pods and services within the same kubernetes cluster, but not outside that network. </p> </li> <li> <p><code>kubectl</code> can create a proxy that will forward communications into cluster-wide, private network. (But how? Show me the code). <code>kubectl</code> interacting through an API endpoint(Wtf?) to communicate with application.</p> </li> <li> <p>This is how, we use a second terminal to open the proxy:</p> </li> </ol> <pre><code>kubectl proxy\n</code></pre> <p>So, this is the understanding, <code>kubectl</code> is a piece of program that is run in the bash terminal(host pc).  After the proxy execution, we now have a connection between our host(terminal) and the Kubernetes cluster. The proxy enables direct access to the API through terminals. - Once this proxy is set, it means we have set up the communications between host and Kubernetes cluster. But how do we actually interact with the pod? - what it actually happens, is that the proxy will automatically set up proxy endpoints (similar like <code>http://proxy/endpoints</code>) for each pods and we can actually query the APIs for individual pods by using internet protocols with <code>curl</code> command, for example.   - You can see all those APIs hosted through the proxy endpoint, now available at through http://localhost:8001. For example, we can query the version directly through the API using the curl command:     <code>curl http://localhost:8001/version</code>   - The API server will automatically create an endpoint for each pod, based on the pod name, that is also accessible through the proxy.   - we can get all the pods name and store it in an environment variable POD_NAME (on the host)     <code>export POD_NAME=$(kubectl get pods -o go-template --template '{{range .items}}{{.metadata.name}}{{\"\\n\"}}{{end}}')</code></p>","tags":["Kubernetes","docker"]},{"location":"blog/2017-12-06-Kubernetes/#summary-of-this-section","title":"Summary of this section","text":"","tags":["Kubernetes","docker"]},{"location":"blog/2017-12-06-Kubernetes/#terms-and-concepts","title":"terms and concepts","text":"Terms Concepts Kubernetes Cluster (KC) The actual cluster that contains many nodes(VMs or physical PCs) Kubernetes Sometimes indicate the program that organize the KC, managing the application deployment and scheduling. Containerize Application is packed in a way that is independent from its environment Master node A special node in the KC. Its main tasks are scheduling and controlling the applications that are running in the normal KC nodes. So, in this sense, the master node controls the normal nodes. In analogy, this nodes is like a manager Nodes The actual PCs or VMs that are used for running the applications. In analogy, these nodes are like workers. Kubelet A piece of software (called \"agent\" in Kubernetes official document) that taking control of an actual node, and managing the communication with master. Every node has a Kubelet. Docker/rkt This is a tool to handle containerized applications. Since every node needs to run containerize application, node needs a tool that can be used to manage these applications. minikube A simple Kubernetes cluster implementation. It only contains 1 Node. kubectl The command line interface that is used to interact with the Kubernetes program. So this \"kubectl\" is actually independent of Kubernetes cluster and nodes. Deployment configuration A configuration file that tells the Kubernetes Cluster how to configure and deploy your applications. Then the master node will then load this file and deploy the applications to nodes. The deployment can also be done by using the \"kubectl\" command line interface. Deployment controller Once the application is deployed on nodes, a Deployment controller will take in charge to monitor all these applications. If nodes goes down or deleted, the deployment controller will replace it with new one. pods(?) The concept of this is not quite clear yet. To me, it is more like a running instance of an application. There may be more than one instance of applications. In analogy, the pods is like an instance of a class, there are maybe several instances of same class. (<code>dog = Animal(); cat = Animal()</code>, <code>dog</code> and <code>cat</code> are similar to pods) Proxy(?) The KC is more like a network, where as each pod is act like an user in the KC network. In the KC,  a proxy build up a communication channel that allows the pods to be able to communicate with each other. endpoint(?) Every pods can be linked to the proxy with an address. In my understanding, this address can be referred as endpoint.","tags":["Kubernetes","docker"]},{"location":"blog/2017-12-26-docker-grpc-network/","title":"A simple example of using docker container to realize the grpc client and server communication","text":"<p>First, build a docker container that contains all required packages. In this example, I choose ubuntu:bionic as the basic image, and I installed other packages onto it.</p> <pre><code>FROM ubuntu:bionic\nRUN apt-get update\nRUN apt-get install python3 -y\nRUN apt-get install python3-pip -y\nRUN pip3 install grpcio\n\nADD app /app/\n\nEXPOSE 22222\n</code></pre> <p>The <code>Dockerfile</code> is shown above. In the <code>app</code> file, it contains 4 files. They are:</p> <p>client.py, server.py, test_pb2.py, test_pb2_grpc.py</p> <p><code>test_pb2.py</code> and <code>test_pb2_grpc.py</code> is generated by compiling the <code>test.proto</code>file.  The content for <code>test.proto</code> is shown below.</p> <pre><code>syntax = \"proto3\";\n\npackage lmjwtest;\n\n// service, encode a plain text \nservice EncodeService {\n    // request a service of encode\n    rpc GetEncode(plaintext) returns (encodetext) {}\n}\n\n\nmessage plaintext {\n    string pttransactionID = 1;\n    string ptproperties = 2;\n    string ptsenderID = 3;\n}\n\nmessage encodetext {\n    string enctransactionID = 1;\n    string encproperties = 2;\n    string encsenderID = 3;\n}\n</code></pre> <p>By using the grpcio-tools to compile the <code>test.proto</code>file, we can get the <code>test_pb2.py</code> and <code>test_pb2_grpc.py</code> two files.</p> <p>The compile command is:</p> <pre><code>python3 -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. test.proto\n</code></pre> <p>Then we create the server and client using the grpc generated python file.</p> <p>The server.py file:</p> <pre><code>from concurrent import futures\nimport base64\nimport time \n\nimport test_pb2\nimport test_pb2_grpc\n\nimport grpc\n\ndef encoding(msg):\n    return base64.a85encode(msg.encode())\n\nclass EService(test_pb2_grpc.EncodeServiceServicer):\n\n    def GetEncode(self, request, context):\n        return test_pb2.encodetext(enctransactionID = encoding(request.pttransactionID),\n                                            encproperties = encoding(request.ptproperties),\n                                            encsenderID = request.ptsenderID)\n\ndef serve():\n    server = grpc.server(futures.ThreadPoolExecutor(max_workers=2))\n    test_pb2_grpc.add_EncodeServiceServicer_to_server(EService(),server)\n    server.add_insecure_port('[::]:22222')\n    server.start()\n    try:\n        while True:\n            time.sleep(60*60*24)\n    except KeyboardInterrupt:\n        server.stop(0)\n\nif __name__ == '__main__':\n    serve()\n</code></pre> <p>the client.py:</p> <pre><code>import grpc\n\nimport test_pb2\nimport test_pb2_grpc\n\ndef run():\n    channel = grpc.insecure_channel('server:22222')\n    stub = test_pb2_grpc.EncodeServiceStub(channel)\n    response = stub.GetEncode(test_pb2.plaintext(pttransactionID = 'abcde',\n    ptproperties = 'This is a plain text transaction',\n    ptsenderID = 'Will smith'))\n    print(\"Encdded service received:\\n EnctransactionID:%s\\n,Encproperties:%s\\n,EncsenderID:%s\\n\"%(response.enctransactionID,response.encproperties,response.encsenderID))\n\nif __name__ == \"__main__\":\n    run()\n</code></pre> <p>To test the grpc on the local host, we can open two terminal. The first terminal runs the server.py and the second runs the client.py. If the client.py can return the encoded message, it proves the grpc is working properly on the local host.</p> <p>The Next step is to deploy this simple application on docker containers and the client and server need to be on different containers. So the encoding is considered as a microservice. To do this, we need to run two containers. </p> <p>Using command <code>docker build .</code> to generate the docker images from the dockerfile. Note that you need to create an app folder and copy the \"client.py, server.py, test_pb2.py, test_pb2_grpc.py\" into this folder.</p> <p>the file tree should look like this</p> <pre><code>-somename\n    -Dockerfile\n    -app/\n        -client.py\n        -server.py\n        -test_pb2.py\n        -test_pb2_grpc.py\n</code></pre> <p>run <code>docker build .</code> in the directory \"somename\". This should create a docker image. Copy the created image ID <code>image-id</code>.</p> <p>Using <code>docker run -it image-id</code>, replace the <code>image-id</code> with your image ID that was created by docker build. You need to do this twice in two different command line so that you have two different container. Find the two container ID. In the following code, I use <code>container1</code> and <code>container2</code> to identify two different containers id.</p> <p>The next step is to link this two containers via an network. We can use <code>docker network</code> command to achieve this.</p> <p>open a third terminal and type:</p> <pre><code>docker network create testnet\n</code></pre> <pre><code>docker network connect testnet container1 --alias client\ndocker network connect testnet container2 --alias server\n</code></pre> <p>If you have gone through the code carefully, you may wondering where was the ''server:22222\" come from in <code>client.py</code>  code. Well, here is it. The fact is we name the container2  using the network alias as \"server\" so all the containers in this network can use \"server\" to find this container. You can also use the container ID to replace \"server\".</p> <p>So now, you can run the command <code>python3 app/server.py</code> on the container2 and run <code>python3 app/client.py</code> on the container1. You should be able to see the client side successfully get the encoded message from server. </p> <p>WELL DONE! Now, we have realized the comunication between two containers with grpc!</p> <p>That's all about this post. Let me know if you have any questions. </p>","tags":["Docker","grpc","network"]},{"location":"blog/2018-01-05-OpenSSL-basic-concepts/","title":"Open SSL certificate authority","text":"<p>Statement: This is just a study notes in order to understand the Open SSL and some relating concepts. A lot of contents in this article are copied from Jamie Nguyen's blog OpenSSL Certificate Authority</p>","tags":["openssl"]},{"location":"blog/2018-01-05-OpenSSL-basic-concepts/#article-summarywithout-certificate-revocation-lists","title":"Article summary(without Certificate revocation lists)","text":"<p>The following graph summarizes the relationship between different keys and certificates. </p>","tags":["openssl"]},{"location":"blog/2018-01-05-OpenSSL-basic-concepts/#certificate-authority","title":"Certificate authority","text":"<p>A certificate authority (CA) is an entity that signs digital certificates. Many websites need to let their customers know that the connection is secure, so they pay an internationally trusted CA (eg, VeriSign, DigiCert) to sign a certificate for their domain.</p> <p>In some cases it may make more sense to act as your own CA, rather than paying a CA like DigiCert. Common cases include securing an intranet website, or for issuing certificates to clients to allow them to authenticate to a server (eg, Apache, OpenVPN).</p>","tags":["openssl"]},{"location":"blog/2018-01-05-OpenSSL-basic-concepts/#ca-root-keypair","title":"CA-ROOT-keypair","text":"<ul> <li>root key (ca.key.pem)[private]</li> <li>root certificate (ca.csrt.pem)[Public]</li> </ul> <p>Typically, the root CA does not sign server or client certificates directly. The root CA is only ever used to create one or more intermediate CAs, which are trusted by the root CA to sign certificates on their behalf. </p> <p>root key can be used to create a root certificate. </p> <p>Use the root key (<code>ca.key.pem</code>) to create a root certificate (<code>ca.cert.pem</code>). Give the root certificate a long expiry date, such as twenty years. Once the root certificate expires, all certificates signed by the CA become invalid.</p>","tags":["openssl"]},{"location":"blog/2018-01-05-OpenSSL-basic-concepts/#intermediate-ca","title":"Intermediate CA","text":"<p>An intermediate certificate authority (CA) is an entity that can sign certificates on behalf of the root CA. The root CA signs the intermediate certificate, forming a chain of trust.</p> <p>The purpose of using an intermediate CA is primarily for security. The root key can be kept offline and used as infrequently as possible. If the intermediate key is compromised, the root CA can revoke the intermediate certificate and create a new intermediate cryptographic pair.</p> <ul> <li> <p>Create an intermediate key [private]</p> </li> <li> <p>use the intermediate key to create a certificate signing request (CSR)</p> </li> <li> <p>Create the intermediate certificate(cert, crt) (using the root key?)</p> </li> <li> <p>Input: .csr</p> </li> <li> <p>output: .crt(.cert)</p> </li> <li> <p>Create the certification chain file</p> </li> <li> <p>When an application (eg, a web browser) tries to verify a certificate signed by the intermediate CA, it must also verify the intermediate certificate against the root certificate. To complete the chain of trust, create a CA certificate chain to present to the application.</p> <pre><code>&gt;To create the CA certificate chain, concatenate the intermediate and root certificates together. We will use this file later to verify certificates signed by the intermediate CA.\n</code></pre> </li> </ul>","tags":["openssl"]},{"location":"blog/2018-01-05-OpenSSL-basic-concepts/#sign-server-and-client-using-intermediate-ca","title":"Sign server and client using intermediate CA","text":"<p>We will be signing certificates using our intermediate CA. You can use these signed certificates in a variety of situations, such as to secure connections to a web server or to authenticate clients connecting to a service.</p> <ul> <li> <p>Create private key for server and client</p> </li> <li> <p>Our root and intermediate pairs are 4096 bits. Server and client certificates     &gt; normally expire after one year, so we can safely use 2048 bits instead. </p> </li> <li> <p>Use the private key to create a certificate signing request (CSR)</p> </li> <li> <p>The CSR details don\u2019t need to match the intermediate CA. For server certificates, the     &gt; Common Name must be a fully qualified domain name (eg, <code>www.example.com</code>),     &gt; whereas for client certificates it can be any unique identifier (eg, an e-mail     &gt; address). Note that the Common Name cannot be the same as either your root     &gt; or intermediate certificate.</p> </li> <li> <p>Sign the .csr file</p> </li> <li> <p>To create a certificate, use the intermediate CA to sign the CSR. If the     &gt; certificate is going to be used on a server, use the <code>server_cert</code> extension.     &gt; If the certificate is going to be used for user authentication, use the     &gt; <code>usr_cert</code> extension. Certificates are usually given a validity of one year,     &gt; though a CA will typically give a few days extra for convenience.</p> </li> <li> <p>Deploy the certificate</p> </li> <li> <p>You can now either deploy your new certificate to a server, or distribute the certificate to a client. When deploying to a server application (eg, Apache),you need to make the following files available:</p> <pre><code>&gt; - `ca-chain.cert.pem`\n&gt; - `www.example.com.key.pem`\n&gt; - `www.example.com.cert.pem`\n\n&gt; If you\u2019re signing a CSR from a third-party, you don\u2019t have access to their private key so you only need to give them back the chain file(`ca-chain.cert.pem`) and the certificate (`www.example.com.cert.pem`)\n</code></pre> </li> </ul>","tags":["openssl"]},{"location":"blog/2018-01-05-OpenSSL-basic-concepts/#certificate-revocation-list-crl","title":"Certificate revocation list (CRL)","text":"<p>A certificate revocation list (CRL) provides a list of certificates that have been revoked. A client application, such as a web browser, can use a CRL to check a server\u2019s authenticity. A server application, such as Apache or OpenVPN, can use a CRL to deny access to clients that are no longer trusted.</p> <p>I will stop here just because I do not need this bit for now. Will come back later if needed. </p>","tags":["openssl"]},{"location":"blog/2018-01-05-python-ssl-grpc-implementation/","title":"A python example of realizing secure grpc communication","text":"","tags":["grpc","docker","python"]},{"location":"blog/2018-01-05-python-ssl-grpc-implementation/#useful-links-and-references","title":"Useful links and references:","text":"<p>Here are some links that I found it can be helpful when I was trying to work out how to setup the python ssl communication.</p> <p>Secure gRPC with TLS/SSL, This is golang implementation</p> <p>certstrap, a convienient tool to generate openssl keys and certificate</p> <p>gRPC authentication, the official guide of grpc</p> <p>grpcio, python package, the source code and official document of grpc python</p> <p>grpc golang ssl example, another golang example of ssl communication</p> <p>What is the difference between .pem , .csr , .key and .crt?, a stackexchange question which explains the concepts and differences of different types of files</p> <p>What is a Pem file and how does it differ from other OpenSSL Generated Key File Formats?, a stackexchange question which explains the concepts and differences of different types of files</p> <p>Cannot connect to SSL server using IP address, this is a useful thread that helped me to solve the server certificate problem</p> <p>TLS Golang Server not working with Node-js and Python Client, this thread makes me to understand to set the server certificate to have the name that is the same as the hostname.</p> <p>Go to my GITHUB repository to see the source code implementation.</p>","tags":["grpc","docker","python"]},{"location":"blog/2019-06-12-Intro-to-deep-learning-notes/","title":"Intro to deep learning notes","text":"<p>This is a note for MIT 6.S191 course</p> <p>link</p>","tags":["deep-learning","python"]},{"location":"blog/2019-06-12-Intro-to-deep-learning-notes/#course-1-intro-to-deep-learning","title":"course 1. Intro to deep learning","text":"<p>The Perceptron: Forward Propagation</p> <p>Single layer neural network with tensorflow:</p> <pre><code>from tf.keras.layers import *\n\ninputs = Inputs(m)\nhidden = Dense(d1)(inputs)\n\noutputs = Dense(d2)(hidden)\n\nmodel = Model(inputs, outputs)\n</code></pre> <p>This four lines of code computes the single layer NN.</p> <p>Deep Neural Network</p> <p>More hidden layers</p> <p>Applying Neural Networks</p> <p>Quantifying Loss</p> <p>Compare Predicted loss vs actual loss</p> <p>Minimize loss</p> <p>Different loss functions</p> <ol> <li>Binary cross entropy loss</li> </ol> <pre><code>loss = tf.reduce_mean(\n  tf.nn.softmax_cross_entropy_with_logits(\n    model.y,\n    model.pred\n    ))\n</code></pre> <ol> <li>Mean squared error loss</li> </ol> <pre><code>loss = tf.reduce_mean(\n  tf.square(\n    tf.subtract(model.y, model.pred)\n  )\n)\n</code></pre> <p>Training Neural Network</p> <p>Find <code>W</code> matrices that results the minimum loss</p> <ul> <li>Gradient descent</li> </ul> <pre><code># randomly initialize W\nweights = tf.random_normal(shape, stddev=sigma)\n\n# loop over the following two steps\n# 1. gradient\ngrads = tf.gradients(ys=loss, xs=weights)\n# 2. update weights\nweights_new = weights.assign(weights - lr * grads)\n# until grads converge\n# return the weights\n</code></pre> <p>Neural Network in practice</p> <ul> <li>Learning rate is hard to set</li> <li>try out</li> <li>Design adaptive learning rates<ul> <li>Methods</li> <li>Momentum <code>tf.train.MomentumOptimizer</code></li> <li>Adagrad <code>tf.train.AdagradOptimizer</code></li> <li>Adadelta <code>tf.train.AdadeltaOptimizer</code></li> <li>Adam <code>tf.train.AdamOptimizer</code></li> <li>RMSProp <code>tf.train.RMSPropOptimizer</code></li> </ul> </li> </ul> <p>Mini-batching Gradient descent</p> <ul> <li>can utilize GPU to do the gradient descent</li> </ul> <p>The problem of Over-fitting</p> <p>Regularization</p> <p>avoid over-fitting</p> <p>Regularization method</p> <ol> <li>Dropout randomly <code>tf.keras.layers.Dropout(p=0.5)</code></li> <li>Early stopping. stop training before over-fitting</li> <li>training loss should always decay</li> <li>if validation set loss start to grow, we will just stop training here</li> </ol> <p>Core Fundation Review</p> <ol> <li>The Perception</li> </ol> <pre><code>y = g({x}*[W]+w0)\n</code></pre> <ol> <li> <p>Neural Networks, how does it work</p> </li> <li> <p>Training in practice, over-fitting, etc.</p> </li> </ol>","tags":["deep-learning","python"]},{"location":"blog/2019-11-24-Data-Oriented-Design/","title":"Data Oriented Design","text":"<p>Check out the video. This explains the AOS and SOA very well. data orientied design</p> <p>The following code is a common pattern in Object oriented programming.</p> <pre><code>struct Entity{\n  v3 postion,\n  v3 velocity,\n  int flag,\n\n  virtual void update()\n}\n\nstruct Player: public Entity{\n  float life,\n  float mana,\n\n  void update() override;\n}\n\nstruct Monster: public Entity{\n  float life,\n\n  void update() override;\n}\n\nsturct Door: public Entity{\n  bool current_status,\n  float open_target,\n\n  void update();\n}\n</code></pre> <p>There are few problems with this approach:</p> <ol> <li> <p>Memory allocation. In this objected orientied approach, because we inherited Entity objects and added some fields in child object, the size of the new Object can have different sizes. So, we may ends up as many different size objects which will imply random heap allocation in memory. (just like objects are putting every where in memory without organize) So when we want to access these objects, the speed of accessing all these object can be a bit slow.</p> </li> <li> <p>L1 Cache miss. Let's say we want to update the postion of a player, we use the equation <code>'p = p + v*dt</code>. To update the object state, we will need to know two fields stored in the obejct, the <code>position</code> and the <code>velocity</code> of the object. But, to access these fields, we will need to get all the structure in the L1 cache. So in the end, we fetched all the struct into L1 cache, but we only used two fields. This is something called caches misses.</p> </li> <li> <p>The object oriented approach is also messy in terms of state management, and this can be expensive. Say a player hit a monster, the monster has its own state like how much life it has. But because of object oriented design, the state is kept private to monster, so eventually monster will need to have a method like <code>get_damage</code>. Eventually, we will need to load <code>player</code> object and then call the <code>get_damage</code> method of monster object. But what all we do is probably manipulate the <code>life</code> field, but we will need to fully load the <code>player</code> struct and <code>monster</code> struct, which may contain many other fields and method.</p> </li> </ol> <p>So, what is data oriented design and how can it solve this problem?</p> <p>The difference of object oriented design and data oriented design is a difference between <code>Array Of Struts</code>(AOS) and <code>Strut of Arrays</code>(SOA). Lets see how AOS and SOA are stored in memory</p> <pre><code>struct ood{\n  type_A a,\n  type_B b,\n  type_C c\n}\n\nstruct dod{\n  type_A a[1000],\n  type_B b[1000],\n  type_C c[1000]\n}\n\n// memory\n// OOD (Object orentied design)\n// ...|a|b|c|...|a|b|c|...|a|b|c|...\n//\n// DOD (data orentied design)\n// ...|a|a|a|...|b|b|b|...|c|c|c|...\n//\n// say we need to update a&amp;b field for all structs. The first OOD case, we will\n// need to go through all the structs, fetch the whole struct into L1 cache, then\n// update field a,b, then iterate all the structs. Although we read C field in the\n// L1 Cache, we did not use it at all. We have about 33% cach missing rate. This\n// number is more significant if the object is bigger.\n//\n// But for DOD case, we will just need to pull all field of a and b, and just updates\n// these fields. We have almost 100% cache usagage, which will be much faster.\n</code></pre> <p>For the latter case, because in the memory, the same data is more closely aligned with same type, therefore it is more easy for cpu to do hardware optimization(hardware prefetching). In addition to that, this kind of structure makes SIMD (single instruction mulitple data) very easy.</p> <p>What is SIMD?</p> <p>SIMD is kind like hardware circle for some instruction which runs really fast and in paralle. SIMD allows same instructs for different data to execute in paralle to speed up the computation. SIMD is supported by some modern CPUs. With data orentied design, it can better utilize the SIMD to do the calculation as all our data is aligned nicely in memory.</p>","tags":["cpp"]},{"location":"blog/2021-05-17-Notes-about-learning-OS-dev/","title":"Notes about learning OS dev: [1] A minimal kernel","text":"<p>Below are list of references that I used to learn</p> <ul> <li>A minimal Multiboot Kernel</li> <li>HelloOS</li> </ul>","tags":["OS","kernel"]},{"location":"blog/2021-05-17-Notes-about-learning-OS-dev/#what-is-the-minimal-settingconfiguration-we-need-to-have-so-we-can-boot-a-minimal-kernel","title":"What is the minimal setting/configuration we need to have so we can boot a minimal kernel?","text":"<p>Assuming we are using GRUB boot loader, it seems to me we need to have 4 files to be able to boot a minimal kernel.</p> <pre><code>\u2026\n\u251c\u2500\u2500 Makefile\n\u2514\u2500\u2500 src\n    \u2514\u2500\u2500 arch\n        \u2514\u2500\u2500 x86_64\n            \u251c\u2500\u2500 multiboot_header.asm\n            \u251c\u2500\u2500 boot.asm\n            \u251c\u2500\u2500 linker.ld\n            \u2514\u2500\u2500 grub.cfg\n</code></pre> <p>Let's go through these files one by one.</p>","tags":["OS","kernel"]},{"location":"blog/2021-05-17-Notes-about-learning-OS-dev/#multiboot_headerasm","title":"<code>multiboot_header.asm</code>","text":"<p>To know what is this, we need to know how boot works. (assuming we use BIOS firmware standard)</p> <pre><code>  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502        \u2502       \u2502         \u2502       \u2502                            \u2502        \u2502           \u2502\n  \u2502Power On\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502Load BIOS\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502Switch control to Bootloader\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502Load kernel\u2502\n  \u2502        \u2502       \u2502         \u2502       \u2502                            \u2502        \u2502           \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>In general, we will be using an existing bootloader, such as GRUB (which uses multiboot specification). In order to tell the bootloader our kernel will support the multiboot specification, we will need to have a multiboot header to let the bootloader that we are supporting multiboot.</p> <pre><code>section .multiboot_header\nheader_start:\n    dd 0xe85250d6                ; magic number (multiboot 2)\n    dd 0                         ; architecture 0 (protected mode i386)\n    dd header_end - header_start ; header length\n    ; checksum\n    dd 0x100000000 - (0xe85250d6 + 0 + (header_end - header_start)) ; small hack to avoid compiler warning\n\n    ; insert optional multiboot tags here\n\n    ; required end tag\n    dw 0    ; type\n    dw 0    ; flags\n    dd 8    ; size\nheader_end: ; end of the file\n</code></pre>","tags":["OS","kernel"]},{"location":"blog/2021-05-17-Notes-about-learning-OS-dev/#bootasm","title":"<code>boot.asm</code>","text":"<p>Now the bootloader understands that we are using multiboot, what's the next?</p> <p>We need to add some code that bootloader can call. The way we do it is using <code>boot.asm</code></p> <pre><code>global start  ; export a lable\n\nsection .text ; default section for executing code\nbits 32       ; specify the following lines are 32 bit execution\nstart:\n    ; print `OK` to screen\n    mov dword [0xb8000], 0x2f4b2f4f\n    hlt ; tell CPU to stop\n</code></pre> <p>This basically defines a \"function\" but in assembly, it \"prints\" \"OK\" to screen and halt the CPU.</p>","tags":["OS","kernel"]},{"location":"blog/2021-05-17-Notes-about-learning-OS-dev/#linkerld","title":"<code>linker.ld</code>","text":"<p>Although the previous two steps, we have some assembly code, but we just prepare some seperate bits for different purposes, but they are not working together yet. We will combine them into an <code>ELF</code> executable so it can be run by the GRUB bootloader. The way we do this is through a <code>linker.ld</code> file.</p> <pre><code>ENTRY(start) /*entry point of the kernel*/\n\nSECTIONS {\n    . = 1M; /*conventional load address*/\n\n    .boot :\n    {\n        /* ensure that the multiboot header is at the beginning */\n        *(.multiboot_header)\n    }\n\n    .text :\n    {\n        *(.text)\n    }\n}\n</code></pre> <p>The commands we can run to get the ELF executable.</p> <pre><code>&gt; nasm -f elf64 multiboot_header.asm\n&gt; nasm -f elf64 boot.asm\n&gt; ld -n -o kernel.bin -T linker.ld multiboot_header.o boot.o\n</code></pre> <p>Note: It's important to pass the -n (or --nmagic) flag to the linker, which disables the automatic section alignment in the executable. Otherwise the linker may page align the .boot section in the executable file. If that happens, GRUB isn't able to find the Multiboot header because it isn't at the beginning anymore.</p> <p>After this step, we have an ELF executable called <code>kernel.bin</code>. But how can we <code>run</code> this kernel? This would require our to go to next step.</p>","tags":["OS","kernel"]},{"location":"blog/2021-05-17-Notes-about-learning-OS-dev/#grubcfg","title":"<code>grub.cfg</code>","text":"<p>The <code>grub.cfg</code> is a config file of GRUB. And this file can also be used to create ISO. It is very simple to create an ISO.</p>","tags":["OS","kernel"]},{"location":"blog/2021-05-17-Notes-about-learning-OS-dev/#create-a-new-iso-approach","title":"Create a new ISO approach","text":"<ol> <li>create a folder structure like this</li> </ol> <pre><code>isofiles\n\u2514\u2500\u2500 boot\n    \u251c\u2500\u2500 grub\n    \u2502   \u2514\u2500\u2500 grub.cfg\n    \u2514\u2500\u2500 kernel.bin\n</code></pre> <ol> <li>What's in the <code>grub.cfg</code>?</li> </ol> <pre><code>set timeout=0\nset default=0\n\nmenuentry \"my os\" {\n    multiboot2 /boot/kernel.bin\n    boot\n}\n</code></pre> <ol> <li>run command <code>grub-mkrescue -o os.iso isofiles</code>. We will get an <code>os.iso</code> to be used for boot.</li> </ol> <p>For example, we can boot our OS using <code>qemu-system-x86_64 -cdrom os.iso</code></p>","tags":["OS","kernel"]},{"location":"blog/2021-05-17-Notes-about-learning-OS-dev/#using-host-os-to-boot","title":"Using host OS to boot","text":"<p>However, we can also load the ELF file on exist OS without creating an ISO file. To add the option to boot from our new OS, we can add the following text in <code>/boot/grub/grub.cfg</code></p> <pre><code>menuentry \"my os\" {\n    insmod part_msdos\n    insmod ext2\n    set root='hd0,msdos4'         # `df /boot/` -&gt; `/dev/sda4` -&gt; `hd0,msdos4`\n    multiboot2 /boot/kernel.bin\n    boot\n}\n</code></pre> <p>Then we copy our <code>kernel.bin</code> into <code>/boot/</code>. If we reboot. This should work as well.</p>","tags":["OS","kernel"]},{"location":"blog/2021-05-17-Notes-about-learning-OS-dev/#conclusion","title":"Conclusion","text":"<p>To summarize, we will mainly need 4 parts to be able to boot from a minimal kernel.</p> <ol> <li>we need to tell bootloader GRUB what specification we are using (eg. mutiboot specification) -&gt; <code>multiboot.asm</code></li> <li>we need to have a kernel program that can be run -&gt; <code>boot.asm</code></li> <li>we need to create a ELF executable (combine header + kernel program) -&gt; <code>kernel.bin</code></li> <li>we need to have a config to tell GRUB how to install/run the OS we created -&gt; <code>grub.cfg</code></li> </ol>","tags":["OS","kernel"]},{"location":"blog/OOPDesignNotes/","title":"2022-04-02-OOP design notes","text":"","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#decomposition-generalization","title":"Decomposition &amp; Generalization","text":"","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#association","title":"Association","text":"<p>Loosely coupled relationship between two objects. Below are the code representation.</p> <p>UML represents this with solid line.</p> <pre><code>public class Student{\n    public void play(Sport sport){\n        ...\n    }\n}\n\npublic class Wine{\n    public void pair( food){\n        ...\n    }\n}\n</code></pre>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#aggregation","title":"Aggregation","text":"<p>More like <code>has a</code> relationship where a whole has parts that belong to it. The code example is below.</p> <p>Uml represents with empty diamond. Diamond is on the class that has other class.</p> <pre><code>public class Airliner{\n    private ArrayList&lt;CrewMember&gt; crew;\n\n    public Airliner(){\n        crew = new ArrayList&lt;CrewMember&gt;();\n    }\n    public void add(CrewMember crewMember) {\n        ...\n    }\n}\n\npublic class PetStore{\n    private ArrayList&lt;Pet&gt; pets;\n\n    public PetStore(){\n        pets = new ArrayList&lt;Pet&gt;();\n    }\n    public void add(Pet pet){\n        ...\n    }\n}\n</code></pre>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#composition","title":"Composition","text":"<p>Strong has a relation. Parts needs to co-exist. e.g. House &amp; Room. Room will not be exist without a house. See the example code.</p> <p>UML represent this with a solid diamond. Diamond is on the class that has the other class.</p> <pre><code>public class Human{\n    private Brain brain;\n\n    public Human(){\n        brain = new Brain();\n    }\n}\n\npublic class Employee {\n    private Salary salary;\n\n    public Employee(){\n        salary = new Salary();\n    }\n}\n</code></pre>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#generalization-with-inheritance","title":"Generalization with inheritance","text":"<p>UML: a empty arrow. Superclass is the head of arrow and subclass is the tail of the arrow.</p>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#generalization-with-interfaces","title":"Generalization with Interfaces","text":"<p>UML: empty arrow with dash line. The head of arrow points to the interface and the tail of arrow is the class implements the interface.</p> <p>Interface are used to describe behaviors. E.g.</p> <pre><code>public interface IAnimal{\n    public void move();\n    public void speak();\n    public void eat();\n}\n\npublic class Dog implement IAnimal{\n    public void move() {...}\n    public void speak() {...}\n    public void eat() {...}\n}\n\n// assume the movement of the vehicle\npublic interface IVehicleMovement{\n    public void moveOnX();\n    public void moveOnY();\n}\n\npublic interface IVehicleMovement3D extends IVehicleMovement {\n    public void moveOnZ();\n}\n</code></pre>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#coupling-cohesion","title":"Coupling &amp; Cohesion","text":"<p>Technics to evaluate the design complexity. (Average person can only handle 7 thing at the same time)</p> <ul> <li>Coupling: complexity between modules</li> <li>Cohesion: complexity within the simple module</li> </ul>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#coupling","title":"Coupling","text":"<p>we want loosely coupled module. How do we evaluate our module? whether they are tightly coupled or not?</p> <ul> <li>Degree</li> <li>Ease</li> <li>Flexibility</li> </ul>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#degree","title":"Degree","text":"<p>Number of the connections between the module and others. With coupling, you want to keep the degree small. For instance, if the module needed to connect to other modules through a few parameters or narrow interfaces, then the degree would be small, and coupling would be loose.</p>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#ease","title":"Ease","text":"<p>How obvious are the connections between the module and others. With coupling, you want the connections to be easy to make without needing to understand the implementations of the other modules.</p>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#flexibility","title":"Flexibility","text":"<p>Flexibility is how interchangeable the other modules are for this module. With coupling, you want the other modules easily replaceable for something better in the future.</p>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#cohesion","title":"Cohesion","text":"<p>Cohesion represents the clarity of the responsibilities of a module.</p> <ul> <li>High cohesion: one task and nothing else (clear purpose)</li> <li>Low cohesion: more than one task or unclear purpose</li> </ul> <p>You want high cohesion for your module.</p>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#example","title":"Example","text":"<pre><code>public class Sensor {\n    public double get(controlFlag: int){\n        switch (controlFlag){\n            case 0:\n                return this.humidity;\n                break;\n            case 1:\n                return this.temperature;\n                break;\n            default:\n                throw new UnknowControlFlagException();\n        }\n    }\n}\n</code></pre> <p>This above example is tight coupling &amp; high cohesion. </p> <ul> <li>the class has two purpose, which violates the cohesion principle. This is low   cohesion.</li> <li>the get method is not clear. What is <code>ControlFlag</code> mean? we need to check the   code to see how it works. This is tight coupling.</li> </ul> <p>New design</p> <pre><code>public interface ISensor{\n    public double get(){}\n}\n\npublic class HumiditySensor implements ISensor{\n    public double get() {\n        return this.humidity;\n    }\n}\n\npublic class TemperatureSensor implements ISensor{\n    public double get() {\n        return this.temperature;\n    }\n}\n</code></pre>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#separation-of-concerns","title":"Separation of Concerns","text":"<p>Software design goal: create software that is Flexible, Reusable and Maintainable.</p> <p>One principle is <code>Separation of Concerns</code>. What is a <code>Concern</code>?</p> <p>Concern: A concern is a very general notion, basically it is anything that matters in providing a solution to a problem. </p> <p>Example: Think about supermarket. The concerns for supermarket would be: - how do I store the meat? - how do I bake bread? - how do I accept payment? - how do I stock the shelf?</p> <p>These concerns matters when running the business to serve their customers. How does the supermarket handle this concerns?</p> <p>There's separate department focus on each concern. Each concern poses unique subproblem and each department knows how to handle them. This is separation of concerns.</p> <p>Concerns in software: How these abstractions are implemented in the software can lead to more concerns. Some of these concerns may involve: - what information on the implementation represents - what it manipulates - what gets presented at the end</p> <p>This is an ongoing process.</p>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#dog-example-of-separation-of-concerns","title":"Dog example of separation of concerns","text":"<p>Example code:</p> <pre><code>public class Dog{\n    public String eatFood(Food: food) {\n        ///\n    }\n}\n\npublic class Food{}\n</code></pre> <p>which action dog can do it on its own, which action dog needs something to help.</p> <ul> <li>Who is actually giving dog food?</li> <li>Does dog always have food to eat?</li> <li>Or is dog given food to eat by its owner?</li> </ul> <p>In reality, dog can eat food, but it doesn't know anything about food until its owner feeds it.</p> <p>We needs to separate two concerns, the action of eating, and the action of feeding the food.</p> <pre><code>public class DogOwner{\n    private Dog mydog;\n    private Food dogFood;\n\n    public String feedMyDog(){}\n    public String buyDogFood(){}\n}\n\npublic class Dog{\n    private String name;\n    private Food food;\n    public String eatFood(Food food){}\n}\n\npublic class Food{\n    private String food;\n}\n</code></pre> <p>We removed the concern of how to get food to god from <code>Dog</code> class and let <code>DogOwner</code> handle that issue.</p>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#smartphone-example-of-separation-of-concerns","title":"SmartPhone example of separation of concerns","text":"<p>Another example: smart phone</p> <pre><code>public class SmartPhone{\n    private byte camera;\n    private byte phone;\n\n    public SmartPhone(){}\n\n    public void takePhoto(){}\n    public void savePhoto(){}\n    public void cameraFlash(){}\n\n    public void makePhoneCall(){}\n    public void encryptOutgoingSound(){}\n    public void decipherIncomingSound(){}\n}\n</code></pre> <p>Our SmartPhone class has two concerns: - act as a traditional phone - be able to use the built-in camera to take pictures</p> <p>New design: - separate concern into separate interfaces - implement the interfaces correspondingly</p> <pre><code>public interface ICamera{\n    public void takePhoto();\n    public void savePhoto();\n    public void cameraFlash();\n}\n\npublic interface IPhone {\n    public void makePhoneCall();\n    public void encryptOutgoingSound();\n    public void decipherIncomingSound();\n}\n\npublic class FirstGenCamera implements ICamera{}\npublic class TraditionalPhone implements IPhone{}\n\n\npublic class SmartPhone{\n    private ICamera myCamera;\n    private IPhone myPhone;\n\n    public SmartPhone(ICamera aCamera, IPhone aPhone){\n        this.myCamera = aCamera;\n        this.myPhone = aPhone;\n    }\n\n    public void useCamera(){\n        return this.myCamera.takePhone();\n    }\n    public void usePhone(){\n        return this.myPhone.makePhoneCall();\n    }\n}\n</code></pre>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#information-hiding","title":"Information hiding","text":"<p>Information hiding allows modules of system to give others the minimum amount of information needed to use them correctly and \"hide\" everything else.</p>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#conceptual-integrity","title":"Conceptual integrity","text":"<p>Everyone agree on the same design principle.</p>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#4-design-principle-question","title":"4 design principle question","text":"<ul> <li>Abstraction: what attributes &amp; behavior do you need to model an object through   abstraction?</li> <li>Encapsulation: how are these attributes &amp; behavior are grouped and accessed   through encapsulation?</li> <li>Decomposition: can my class be simplified into smaller parts using decomposition?</li> <li>Generalization: are there common things across my objects that can be   generalized?</li> </ul>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#uml-sequence-diagram","title":"UML Sequence Diagram","text":"<p>A Sequence Diagram describes how objects in your system interact to complete a specific task. So it mainly describes interaction between objects.</p> <ul> <li>class with doted lines (life line)</li> <li>arrows to show message send from one object to the other</li> <li>box represents a Process</li> <li>solid line arrow (send data)</li> <li>dashed line arrow (return data)</li> </ul>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#uml-state-diagram","title":"UML State Diagram","text":"<p>A state diagram is a technique that you can use to describe how your system behaves and responds.</p> <p>state diagram can describe a single object and illustrate how that object behaves in response to a series of events in your system.</p> <p>each state should have: - state name - state variables - activities     - entry     - do      - exit</p>","tags":["OOP","CS"]},{"location":"blog/OOPDesignNotes/#model-checking","title":"Model checking","text":"","tags":["OOP","CS"]},{"location":"blog/PRIVACY_POLICY/","title":"Privacy Policy","text":"<p>Effective Date: 2025-12-25</p> <p>Snap Ledger (\"we,\" \"our,\" or \"us\") is committed to protecting your privacy. This Privacy Policy explains how your information is collected, used, and disclosed by Snap Ledger.</p> <p>This Privacy Policy applies to our application named Snap Ledger.</p>"},{"location":"blog/PRIVACY_POLICY/#1-information-we-collect","title":"1. Information We Collect","text":""},{"location":"blog/PRIVACY_POLICY/#a-information-you-provide-to-us","title":"A. Information You Provide to Us","text":"<p>We collect information you provide directly to us, such as when you create an account, subscribe to our services, or communicate with us.</p>"},{"location":"blog/PRIVACY_POLICY/#b-information-automatically-collected","title":"B. Information Automatically Collected","text":"<ul> <li>Device Information: We may collect information about the mobile device you use to access our App, including the hardware model, operating system and version, unique device identifiers, and mobile network information.</li> <li>Usage Information: We collect information about your use of the App, such as the features you use and the time spent on the App.</li> </ul>"},{"location":"blog/PRIVACY_POLICY/#c-permissions-we-request","title":"C. Permissions We Request","text":"<ul> <li>Camera: We request access to your device's camera to allow you to scan receipts and documents directly within the app. Images are processed locally on your device using on-device machine learning models.</li> <li>Photo Gallery: We request access to your photo gallery to allow you to select and upload existing images for processing.</li> </ul>"},{"location":"blog/PRIVACY_POLICY/#2-third-party-services","title":"2. Third-Party Services","text":"<p>We use the following third-party services which may collect information used to identify you:</p>"},{"location":"blog/PRIVACY_POLICY/#a-google-admob","title":"A. Google AdMob","text":"<p>We use Google AdMob to display advertisements in our App. AdMob may use identifiers such as your Advertising ID to serve personalized ads based on your interests. - Google AdMob Privacy Policy</p>"},{"location":"blog/PRIVACY_POLICY/#b-revenuecat","title":"B. RevenueCat","text":"<p>We use RevenueCat to manage our subscription and in-app purchase infrastructure. RevenueCat may collect anonymous App User IDs and purchase history to validate and manage your subscriptions. - RevenueCat Privacy Policy</p>"},{"location":"blog/PRIVACY_POLICY/#3-how-we-use-your-information","title":"3. How We Use Your Information","text":"<p>We use the information we collect to: - Provide, maintain, and improve our App. - Process transactions and manage your subscriptions. - detailed analysis of receipts using on-device machine learning technologies. - Serve relevant advertisements. - Monitor and analyze trends, usage, and activities in connection with our App.</p>"},{"location":"blog/PRIVACY_POLICY/#4-data-storage-and-security","title":"4. Data Storage and Security","text":"<ul> <li>Local Storage: We use local databases (Isar) and storage (Shared Preferences) to store your data directly on your device.</li> <li>Security: We take reasonable measures to help protect information about you from loss, theft, misuse and unauthorized access, disclosure, alteration and destruction.</li> </ul>"},{"location":"blog/PRIVACY_POLICY/#5-childrens-privacy","title":"5. Children's Privacy","text":"<p>Our Services do not address anyone under the age of 13. We do not knowingly collect personally identifiable information from children under 13.</p>"},{"location":"blog/PRIVACY_POLICY/#6-changes-to-this-privacy-policy","title":"6. Changes to This Privacy Policy","text":"<p>We may update our Privacy Policy from time to time. Thus, you are advised to review this page periodically for any changes. We will notify you of any changes by posting the new Privacy Policy on this page.</p>"},{"location":"blog/PRIVACY_POLICY/#7-contact-us","title":"7. Contact Us","text":"<p>If you have any questions or suggestions about our Privacy Policy, do not hesitate to contact us.</p>"},{"location":"blog/SmallLearning/","title":"2022-03-22-common knowledge cheat sheet","text":"","tags":["rust","CS"]},{"location":"blog/SmallLearning/#rust","title":"Rust","text":"<ul> <li><code>String.push(char)</code> takes char</li> <li><code>Vec</code> has <code>reverse</code> method where as iterator has <code>rev</code> method</li> <li><code>String</code> and <code>&amp;str</code> both have <code>chars</code> method that convert string to <code>Char</code></li> <li><code>String</code> and <code>&amp;str</code> can be <code>split_whitespace</code><ul> <li>they also can call <code>split(pat: P)</code> e.g <code>split(' ')</code> is equivalent to split   by whitespace</li> </ul> </li> <li>NOTE: in rust <code>usize -1</code> could overflow to max, this might causing algorithm   not working properly</li> <li>If we are dealing with linked list with <code>Option&lt;Box&lt;Node&gt;&gt;</code>, we can   potentially using <code>Box::clone()</code> to overcome some limitation due to borrow   checker. <code>Box::clone</code> should be relatively not expensive as mentioned in rust   book: <code>a box is a   smart pointer to a heap allocated value of T</code>.</li> <li>Check if key in HashMap, use <code>HashMap.contains_key(&amp;key)</code>,   <code>HashMap.remove(&amp;key)</code> for delete, <code>HashMap.insert(key, val)</code> for insert key</li> <li><code>*HashMap.entry(&amp;key).or_insert(value) += 1</code> can be used as default map</li> <li>Double side queue: <code>VecDeque</code>, we can <code>push/pop_front</code> and <code>push/pop_back</code></li> <li><code>char</code> can be force convert to <code>u8</code> if we want: <code>'a' as u8</code> </li> <li><code>Rc&lt;RefCell&lt;T&gt;&gt;</code> can be get the internal <code>&amp;mut T</code> by call <code>borrow_mut()</code></li> <li><code>&amp;mut [T]</code> can call <code>&amp;mut [T].clone/copy_from_slice(&amp;[T])</code>, but their length   needs to be the same</li> <li><code>&amp;[T]</code> has method <code>to_vec</code> that can clone it to a new vector</li> <li><code>&amp;mut [T]</code> has <code>rotate_left/right</code>  and <code>reverse</code> method</li> <li><code>Vec&lt;char&gt;</code> can be collect into string using   <code>x.chars().into_iter().collect&lt;String&gt;()</code></li> <li><code>char</code> can use <code>to_uppercase/lowercase()</code> convert to up/lower case characters.</li> <li><code>char</code> has <code>is_ascii_alphabetic</code> method</li> <li><code>slice</code> has method <code>.split_at(usize)</code> so the slice can be split into two parts</li> <li><code>iter</code> has fold method, which allows we to fold iterator. e.g.   <code>rust   vec![1,1,1,2,3].iter().fold(HashMap::new(), |mut map, i|{     let val = map.entry(i).or_insert(0); *val += 1; map   })`   // equals to HashMap{1:3, 2:1, 3:1}</code></li> </ul>","tags":["rust","CS"]},{"location":"blog/SmallLearning/#docker","title":"Docker","text":"<ul> <li>Docker can be run with <code>--network=host</code> on windows, but as stated by   reference, quote: <p>The host networking driver only works on Linux hosts, and is not supported on Docker Desktop for Mac, Docker Desktop for Windows, or Docker EE for Windows Server. </p> </li> </ul> <p>So, when you notice something wired, like cannot ping docker exported port   from windows/wsl2. check if your docker container is launched using   <code>--network=host</code>.</p>","tags":["rust","CS"]},{"location":"blog/WindowKeyMapping/","title":"2021-11-20-Painless key mapping on windows","text":"<p>Recently, I start to using windows for my personal project. One thing I hate about is the keyboard mappings.</p> <p>I want to basically do the following mappings</p> <p>1 Caps lock key -&gt; Left Ctrl key 2 Left Alt key -&gt; Left Ctrl key 3 Left Windows key -&gt; Left Alt key</p> <p>I was using the . The first two key mapping works fine, however, the third mapping has the problem. For example, \"Win+W\" should suppose to map to \"Alt+W\" which corresponding to the \"Copy\" in emacs, however, it opens the \"Pen\" app in the Windows.</p> <p>I did some research, and found another tool, which called the AutoHotKey. Although this tool is quite nice to do some specific customizations, it is not good for my perticular use cases. By looking through the guide on https://www.autohotkey.com/docs/misc/Remap.htm#registry, it points out to a different application, which is called KeyTweak.</p> <p>By using the KeyTweak, I was able to map the \"Win\" key to \"Alt\" key without having any issues.</p>","tags":["tool","key-mapping"]},{"location":"blog/WindowKeyMapping/#useful-infos","title":"Useful infos","text":"<ul> <li>https://superuser.com/questions/1147517/how-to-disable-only-some-windows-10-global-shortuts-to-use-them-in-third-party-a</li> <li>https://www.autohotkey.com/docs/misc/Remap.htm#registry</li> </ul>","tags":["tool","key-mapping"]},{"location":"blog/simple-rust-protobuf-grpc-guide/","title":"Simple tonic/prost example","text":"","tags":["rust","tonic","prost","protobuf","build"]},{"location":"blog/simple-rust-protobuf-grpc-guide/#a-simple-tonic-repo-setup","title":"A simple tonic repo setup","text":"<p>Using gRPC usually requires both client &amp; server to have same protobuf definition. Client and server usually are not defined in the same repository.</p> <p>We can use a separate git repository to store the protobuf definition, and using the git submodule to include the protobuf definition in the corresponding client and server.</p> <p>Check sample repo to see how to setup </p>","tags":["rust","tonic","prost","protobuf","build"]},{"location":"blog/simple-rust-protobuf-grpc-guide/#a-simple-prost-example","title":"A simple prost example","text":"<p>Sometime you only want to use protobuf to do serializing and deserializing the message, nothing else. In this case, you will need to use prost only.</p> <p>Here is a simplest example of how to do that.</p> <p>You may also find the snazzy can be helpful.</p>","tags":["rust","tonic","prost","protobuf","build"]}]}