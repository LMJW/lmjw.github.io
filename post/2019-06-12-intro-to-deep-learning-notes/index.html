<!doctype html><html lang=en>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=HandheldFriendly content="True">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta http-equiv=cache-control content="no-transform">
<meta http-equiv=cache-control content="no-siteapp">
<meta name=generator content="Hugo 0.89.1">
<link rel="shortcut icon" href=https://cdn.jsdelivr.net/gh/dsrkafuu/dsr-cdn-main@1/images/favicons/dsrca.ico>
<title>Intro to deep learning notes - LMJW Blog</title>
<meta name=author content="LMJW">
<meta name=description content="A minimal Hugo theme with nice theme color.">
<meta name=keywords content="deep-learning,python">
<meta property="og:title" content="Intro to deep learning notes">
<meta name=twitter:title content="Intro to deep learning notes">
<meta property="og:type" content="article">
<meta property="og:url" content="https://lmjw.github.io/post/2019-06-12-intro-to-deep-learning-notes/"><meta property="og:description" content="This is a note for MIT 6.S191 course
link
 course 1. Intro to deep learning  The Perceptron: Forward Propagation
Single layer neural network with tensorflow:
from tf.keras.layers import * inputs = Inputs(m) hidden = Dense(d1)(inputs) outputs = Dense(d2)(hidden) model = Model(inputs, outputs)  This four lines of code computes the single layer NN.
 Deep Neural Network
More hidden layers
 Applying Neural Networks
 Quantifying Loss
Compare Predicted loss vs actual loss
 Minimize loss
Different loss functions
 Binary cross entropy loss  loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits( model.y, model.pred ))  Mean squared error loss  loss = tf.">
<meta name=twitter:description content="This is a note for MIT 6.S191 course
link
 course 1. Intro to deep learning  The Perceptron: Forward Propagation
Single layer neural network with tensorflow:
from tf.keras.layers import * inputs = Inputs(m) hidden = Dense(d1)(inputs) outputs = Dense(d2)(hidden) model = Model(inputs, outputs)  This four lines of code computes the single layer NN.
 Deep Neural Network
More hidden layers
 Applying Neural Networks
 Quantifying Loss
Compare Predicted loss vs actual loss
 Minimize loss
Different loss functions
 Binary cross entropy loss  loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits( model.y, model.pred ))  Mean squared error loss  loss = tf."><meta property="og:image" content="https://lmjw.github.io/img/og.png">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://lmjw.github.io/img/og.png"><meta property="article:published_time" content="2019-06-12T00:00:00+00:00"><meta property="article:modified_time" content="2019-06-12T00:00:00+00:00">
<style>@media(prefers-color-scheme:dark){body[data-theme=auto] img{filter:brightness(60%)}}body[data-theme=dark] img{filter:brightness(60%)}</style>
<link rel=stylesheet href=https://lmjw.github.io/assets/css/fuji.min.css>
</head>
<body data-theme=auto data-theme-auto=true>
<script data-cfasync=false>var fujiThemeData=localStorage.getItem('fuji_data-theme');fujiThemeData?fujiThemeData!=='auto'&&document.body.setAttribute('data-theme',fujiThemeData==='dark'?'dark':'light'):localStorage.setItem('fuji_data-theme','auto')</script>
<header>
<div class="container-lg clearfix">
<div class="col-12 header">
<a class=title-main href=https://lmjw.github.io/>LMJW Blog</a>
<span class=title-sub>My notes.</span>
</div>
</div>
</header>
<main>
<div class="container-lg clearfix">
<div class="col-12 col-md-9 float-left content">
<article>
<h2 class="post-item post-title">
<a href=https://lmjw.github.io/post/2019-06-12-intro-to-deep-learning-notes/>Intro to deep learning notes</a>
</h2>
<div class="post-item post-meta">
<span><i class="iconfont icon-today-sharp"></i>&nbsp;2019-06-12</span>
<span><i class="iconfont icon-file-tray-sharp"></i>&nbsp;244 words</span>
<span><i class="iconfont icon-time-sharp"></i>&nbsp;2 minutes</span>
<span><i class="iconfont icon-pricetags-sharp"></i>&nbsp;<a href=/tags/deep-learning>deep-learning</a>&nbsp;<a href=/tags/python>python</a>&nbsp;</span>
</div>
<div class="post-content markdown-body">
<blockquote>
<p>This is a note for MIT 6.S191 course</p>
<p><a href=http://introtodeeplearning.com/ target=_blank>link</a></p>
</blockquote>
<h1 id=course-1-intro-to-deep-learning>course 1. Intro to deep learning</h1>
<hr>
<p><strong>The Perceptron: Forward Propagation</strong></p>
<p>Single layer neural network with <strong>tensorflow</strong>:</p>
<pre><code class=language-python>from tf.keras.layers import *

inputs = Inputs(m)
hidden = Dense(d1)(inputs)

outputs = Dense(d2)(hidden)

model = Model(inputs, outputs)
</code></pre>
<p>This four lines of code computes the single layer NN.</p>
<hr>
<p><strong>Deep Neural Network</strong></p>
<p>More hidden layers</p>
<hr>
<p>Applying Neural Networks</p>
<hr>
<p>Quantifying Loss</p>
<p>Compare <strong>Predicted loss</strong> vs <strong>actual loss</strong></p>
<hr>
<p>Minimize loss</p>
<p><strong>Different loss functions</strong></p>
<ol>
<li>Binary cross entropy loss</li>
</ol>
<pre><code class=language-python>loss = tf.reduce_mean(
  tf.nn.softmax_cross_entropy_with_logits(
    model.y,
    model.pred
    ))
</code></pre>
<ol start=2>
<li>Mean squared error loss</li>
</ol>
<pre><code class=language-python>loss = tf.reduce_mean(
  tf.square(
    tf.subtract(model.y, model.pred)
  )
)
</code></pre>
<hr>
<p><strong>Training Neural Network</strong></p>
<p>Find <code>W</code> matrices that results the minimum loss</p>
<ul>
<li>Gradient descent</li>
</ul>
<pre><code class=language-python># randomly initialize W
weights = tf.random_normal(shape, stddev=sigma)

# loop over the following two steps
# 1. gradient
grads = tf.gradients(ys=loss, xs=weights)
# 2. update weights
weights_new = weights.assign(weights - lr * grads)
# until grads converge
# return the weights

</code></pre>
<hr>
<p><strong>Neural Network in practice</strong></p>
<ul>
<li>Learning rate is hard to set
<ul>
<li>try out</li>
<li>Design adaptive learning rates
<ul>
<li>Methods
<ul>
<li>Momentum <code>tf.train.MomentumOptimizer</code></li>
<li>Adagrad <code>tf.train.AdagradOptimizer</code></li>
<li>Adadelta <code>tf.train.AdadeltaOptimizer</code></li>
<li>Adam <code>tf.train.AdamOptimizer</code></li>
<li>RMSProp <code>tf.train.RMSPropOptimizer</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<p>Mini-batching Gradient descent</p>
<ul>
<li>can utilize GPU to do the gradient descent</li>
</ul>
<hr>
<p>The problem of Over-fitting</p>
<hr>
<p>Regularization</p>
<p>avoid over-fitting</p>
<p><strong>Regularization method</strong></p>
<ol>
<li>Dropout randomly <code>tf.keras.layers.Dropout(p=0.5)</code></li>
<li>Early stopping. stop training before over-fitting
<ol>
<li>training loss should always decay</li>
<li>if validation set loss start to grow, we will just stop training here</li>
</ol>
</li>
</ol>
<hr>
<p><strong>Core Fundation Review</strong></p>
<ol>
<li>The Perception</li>
</ol>
<pre><code class=language-math>y = g({x}*[W]+w0)
</code></pre>
<ol start=2>
<li>
<p>Neural Networks, how does it work</p>
</li>
<li>
<p>Training in practice, over-fitting, etc.</p>
</li>
</ol>
</div>
</article>
<div class="license markdown-body">
<blockquote>
<p>Unless otherwise noted, the content of this site is licensed under <a rel=license href=http://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank>CC BY-NC-SA 4.0</a>.</p>
</blockquote>
</div>
</div>
<aside class="col-12 col-md-3 float-left sidebar">
<div class="sidebar-item sidebar-pages">
<h3>Pages</h3>
<ul>
<li>
<a href=/>Home</a>
</li>
<li>
<a href=/archives/>Archives</a>
</li>
<li>
<a href=/search/>Search</a>
</li>
</ul>
</div>
<div class="sidebar-item sidebar-links">
<h3>Links</h3>
<ul>
<li>
<a href=https://github.com/LMJW target=_blank><span>GitHub</span></a>
</li>
</ul>
</div>
<div class="sidebar-item sidebar-tags">
<h3>Tags</h3>
<div>
<span>
<a href=/tags/bash/>bash</a>
</span>
<span>
<a href=/tags/cli/>CLI</a>
</span>
<span>
<a href=/tags/cpp/>cpp</a>
</span>
<span>
<a href=/tags/deep-learning/>deep-learning</a>
</span>
<span>
<a href=/tags/docker/>docker</a>
</span>
<span>
<a href=/tags/gmp/>GMP</a>
</span>
<span>
<a href=/tags/golang/>golang</a>
</span>
<span>
<a href=/tags/grpc/>grpc</a>
</span>
<span>
<a href=/tags/kernel/>kernel</a>
</span>
<span>
<a href=/tags/kubernetes/>Kubernetes</a>
</span>
<span>
<a href=/tags/markdown-cheatsheet/>Markdown CheatSheet</a>
</span>
<span>
<a href=/tags/network/>network</a>
</span>
<span>
<a href=/tags/openssl/>openssl</a>
</span>
<span>
<a href=/tags/os/>OS</a>
</span>
<span>
<a href=/tags/python/>python</a>
</span>
<span>
<a href=/tags/subprocess/>subprocess</a>
</span>
<span>
<a href=/tags/tools/>Tools</a>
</span>
</div>
</div>
<div class="sidebar-item sidebar-toc">
<h3>Table of Contents</h3><nav id=TableOfContents></nav></div>
</aside>
</div>
<div class=btn>
<div class=btn-menu id=btn-menu>
<i class="iconfont icon-grid-sharp"></i>
</div>
<div class=btn-toggle-mode>
<i class="iconfont icon-contrast-sharp"></i>
</div>
<div class=btn-scroll-top>
<i class="iconfont icon-chevron-up-circle-sharp"></i>
</div>
</div>
<aside class=sidebar-mobile style=display:none>
<div class=sidebar-wrapper>
<div class="sidebar-item sidebar-pages">
<h3>Pages</h3>
<ul>
<li>
<a href=/>Home</a>
</li>
<li>
<a href=/archives/>Archives</a>
</li>
<li>
<a href=/search/>Search</a>
</li>
</ul>
</div>
<div class="sidebar-item sidebar-links">
<h3>Links</h3>
<ul>
<li>
<a href=https://github.com/LMJW target=_blank><span>GitHub</span></a>
</li>
</ul>
</div>
<div class="sidebar-item sidebar-tags">
<h3>Tags</h3>
<div>
<span>
<a href=/tags/bash/>bash</a>
</span>
<span>
<a href=/tags/cli/>CLI</a>
</span>
<span>
<a href=/tags/cpp/>cpp</a>
</span>
<span>
<a href=/tags/deep-learning/>deep-learning</a>
</span>
<span>
<a href=/tags/docker/>docker</a>
</span>
<span>
<a href=/tags/gmp/>GMP</a>
</span>
<span>
<a href=/tags/golang/>golang</a>
</span>
<span>
<a href=/tags/grpc/>grpc</a>
</span>
<span>
<a href=/tags/kernel/>kernel</a>
</span>
<span>
<a href=/tags/kubernetes/>Kubernetes</a>
</span>
<span>
<a href=/tags/markdown-cheatsheet/>Markdown CheatSheet</a>
</span>
<span>
<a href=/tags/network/>network</a>
</span>
<span>
<a href=/tags/openssl/>openssl</a>
</span>
<span>
<a href=/tags/os/>OS</a>
</span>
<span>
<a href=/tags/python/>python</a>
</span>
<span>
<a href=/tags/subprocess/>subprocess</a>
</span>
<span>
<a href=/tags/tools/>Tools</a>
</span>
</div>
</div>
<div class="sidebar-item sidebar-toc">
<h3>Table of Contents</h3>
<nav id=TableOfContents></nav>
</div>
</div>
</aside>
</main>
<footer>
<div class="container-lg clearfix">
<div class="col-12 footer">
<span>&copy; 2020-2021
<a href=https://lmjw.github.io/>LMJW</a>
| <a href=https://github.com/LMJW/lmjw.github.io>Source code</a>
| Powered by <a href=https://github.com/dsrkafuu/hugo-theme-fuji/ target=_blank>Fuji-v2</a> & <a href=https://gohugo.io/ target=_blank>Hugo</a>
</span>
</div>
</div>
</footer>
<script defer src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.23.0/components/prism-core.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.23.0/plugins/autoloader/prism-autoloader.min.js></script>
<script defer src=/assets/js/fuji.min.js></script>
</body>
</html>